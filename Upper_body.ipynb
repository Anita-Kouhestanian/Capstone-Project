{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building upperbody classifier\n",
    "To build an own Haar Cascade, I used \"positive\" images, and \"negative\" images downloaded from Imagenet. The \"positive\" images are images that contain the human that is partially cropped waist-up. With these positives, I built a vector file that is all of these positives put together and  The negative images can be anything, except they cannot contain the object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, after downloding the urls from Imagenet , what I did is write a quick script that will visit these URL lists, grab the links, visit the links, pull the images, resize them, save them, and repeat until we're done. When our directories are full of images, we also need a sort of description file that describes the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def store_raw_images():\n",
    "    neg_images_link = '//image-net.org/api/text/imagenet.synset.geturls?wnid=c75554f'   \n",
    "    neg_image_urls = urllib.request.urlopen(neg_images_link).read().decode()\n",
    "    pic_num = 1\n",
    "    \n",
    "    if not os.path.exists('neg'):\n",
    "        os.makedirs('neg')\n",
    "        \n",
    "    for i in neg_image_urls.split('\\n'):\n",
    "        try:\n",
    "            print(i)\n",
    "            urllib.request.urlretrieve(i, \"neg/\"+str(pic_num)+\".jpg\")\n",
    "            img = cv2.imread(\"neg/\"+str(pic_num)+\".jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "            # should be larger than samples / pos pic (so we can place our image on it)\n",
    "            resized_image = cv2.resize(img, (100, 100))\n",
    "            cv2.imwrite(\"neg/\"+str(pic_num)+\".jpg\",resized_image)\n",
    "            pic_num += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(str(e)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have over 2,000 neg pictures. The next step is to create the descriptor file for these negative images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos_n_neg():\n",
    "    for file_type in ['neg']:\n",
    "        \n",
    "        for img in os.listdir(file_type):\n",
    "\n",
    "            if file_type == 'pos':\n",
    "                line = file_type+'/'+img+' 1 0 0 50 50\\n'\n",
    "                with open('info.dat','a') as f:\n",
    "                    f.write(line)\n",
    "            elif file_type == 'neg':\n",
    "                line = file_type+'/'+img+'\\n'\n",
    "                with open('bg.txt','a') as f:\n",
    "                    f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the code below in terminal to get my positive images based on my sample positive image\n",
    "\n",
    "opencv_createsamples -img watch5050.jpg -bg bg.txt -info info/info.lst -pngoutput info -maxxangle 0.5 -maxyangle 0.5 -maxzangle 0.5 -num 1950\n",
    "\n",
    "bg is the background information, info where we will put the info.list output (which is a lot like the bg.txt file), then the -pngoutput is wherever we want to place the newly generated images. Finally, we have some optional parameters to make our original image a bit more dynamic and then =num for the number of samples we want to try to create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting positive images, I ran code below to train my haarcascade based on neg and pos images\n",
    "\n",
    "opencv_traincascade -data data -vec positives.vec -bg bg.txt -numPos 1800 -numNeg 900 -numStages 10 -w 20 -h 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 stages took a bit less than 2 hours to do on my server. I got 10 xml files in my \"data\" directory and used my last xml as my upperbody classifier. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
